import asyncio
import threading
import crochet
import nmap
from scrapy.crawler import CrawlerProcess,CrawlerRunner
from scrapy.utils.project import get_project_settings
from cmds.scrapyCmd import MySpider

# Initialize crochet
crochet.setup()


# Create a function to run the spider
@crochet.run_in_reactor
def run_spider(spider_url):
    runner = CrawlerRunner(get_project_settings())
    deferred = runner.crawl(MySpider, url=spider_url)
    return deferred

async def async_main():
    run_spider(spider_url="http://192.168.124.128/login")

if __name__ == "__main__":
    asyncio.run(async_main())
