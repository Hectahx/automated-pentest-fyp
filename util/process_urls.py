import re

def process_urls(urls):
    login_urls = []
    sql_lfi_urls = []

    all_urls = {}
    
    login_pattern = re.compile(r'https?:\/\/[\w.-]+(?:\.[\w.-]+)+(?:\/[\w\-\._~:/?#\[\]@!$&\'()*+,;=]*)?(\/login|\/login\.php)(\?[\w\-\._~:/?#\[\]@!$&\'()*+,;=]*)?$')
    sql_lfi_pattern = re.compile(r'https?:\/\/[\w.-]+(?:\.[\w.-]+)+[\w\-\._~:/?#\[\]@!$&\'()*+,;=]*(\?|&)([\w.-]+=[\w.-]+)')
    sql_lfi_urls = [url for url in urls if sql_lfi_pattern.search(url)]
    login_urls = [url for url in urls if login_pattern.search(url)]

    all_urls["login"] = login_urls
    all_urls["sql_lfi"] = filter_unique_url_ids(sql_lfi_urls)

    print("URLs Processed") 
    return all_urls

def filter_unique_url_ids(urls):
    unique_urls = {}
    for url in urls:
        # Split the URL at the '?'
        base_url, query_string = url.split('?')
        # Use the combination of base URL and id as the key
        if base_url not in unique_urls:
            unique_urls[base_url] = url

    # Now get the list of unique URLs
    unique_urls_list = list(unique_urls.values())

    return(unique_urls_list)