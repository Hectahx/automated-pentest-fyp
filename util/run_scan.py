from cmds.sqlmapCmd import run_sqlmap
from cmds.lfimapCmd import run_lfimap
from util.process_urls import process_urls
from util.bs_crawler import crawl
import asyncio

async def run_scan(target):
    collected_urls = []
    max_depth = 3
    crawl(target, max_depth, collected_urls)
    all_urls = process_urls(collected_urls)

    login_urls = all_urls["login"]
    sql_lfi_urls = all_urls["sql_lfi"]

    #This only scans the  first sites of each array, need to change it so all of them are done
    sqlmap_task = asyncio.create_task(run_sqlmap(login_urls[0]))
    lfimap_task = asyncio.create_task(run_lfimap(sql_lfi_urls[0]))

    await asyncio.gather(sqlmap_task, lfimap_task)

    sqlmap_output = sqlmap_task.result()
    lfimap_output = lfimap_task.result()

    results = {
        "target" : target,
        "sqlmap": {"output": sqlmap_output, "is_vulnerable": sqlmap_output[0] if sqlmap_output else False},
        "lfimap": {"output": lfimap_output, "is_vulnerable": lfimap_output[0] if lfimap_output else False}
    }

    return results
