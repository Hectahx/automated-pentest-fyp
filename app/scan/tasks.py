from util.run_scan import run_scan_multi
from ..models import ScanResult
from ..extensions import db
import json
from celery import shared_task
from celery.contrib.abortable import AbortableTask
import asyncio

@shared_task(bind=True, base=AbortableTask)
def complete_scan(self, scan_data):
    print(scan_data)
    scan_dict = json.loads(scan_data)
    print(scan_dict)
    loop = asyncio.get_event_loop()
    results = loop.run_until_complete(run_scan_multi(scan_dict["target"]))




    # Assuming Flask application context is properly managed in your Celery setup
    # You may need to push the context here if not globally managed for the task
    scan_result = ScanResult.query.filter_by(scan_id=scan_dict["scan_id"]).first()
    if scan_result:
        scan_result.scan_data = json.dumps(results)
        scan_result.status = 'completed'
        db.session.commit()
    
    if self.is_aborted():
        return "TASK STOPPED!"
    
    return "DONE!"

'''
async def complete_scan(self, scan_data):
    results = await run_scan_multi(scan_data["target"])

    # Assuming Flask application context is properly managed in your Celery setup
    # You may need to push the context here if not globally managed for the task
    scan_result = ScanResult.query.filter_by(scan_id=scan_data["scan_id"]).first()
    if scan_result:
        scan_result.scan_data = json.dumps(results)
        scan_result.status = 'completed'
        db.session.commit()
    
    if self.is_aborted():
        return "TASK STOPPED!"
    
    return "DONE!"
'''
